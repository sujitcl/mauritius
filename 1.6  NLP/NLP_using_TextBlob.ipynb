{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP using TextBlob"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!pip install TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('brown')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating a textblob object\n",
    "blob = TextBlob('LeBron Raymone James , often referred to mononymously as LeBron, is an American professional basketball player for the Los Angeles Lakers of the NBA. He is often considered the best basketball player in the world ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "\n",
    "Tokenization refers to dividing text or a sentence into a sequence of tokens, which roughly correspond to “words”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, this textblob can be tokenized into a sentence and further into words. Let’s look at the code shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob.sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for words in blob.sentences[1].words:\n",
    "    print (words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noun phrase extraction\n",
    "Noun Phrase extraction is particularly important when you want to analyze the “who” in a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for np in blob.noun_phrases:\n",
    "    print (np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see that isn't correct but we were working with machines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS tagging\n",
    " In simple words, it tells whether a word is a noun, or an adjective, or a verb, etc. This is just a complete version of noun phrase extraction, where we want to find all the the parts of speech in a sentence.\n",
    " \n",
    "For instance -\n",
    "\n",
    "NNS noun plural like- 'desks'\n",
    "\n",
    "NNP proper noun, singular like -'Harrison'\n",
    "\n",
    "NNPS proper noun, plural like- 'Americans'\n",
    "\n",
    "PDT predeterminer like -'all the kids'\n",
    "\n",
    "POS possessive ending like- parent's\n",
    "\n",
    "PRP personal pronoun like- I, he, she\n",
    "\n",
    "PRP$ possessive pronoun like -my, his, hers\n",
    "\n",
    "RB adverb like- very, silently, ...\n",
    "\n",
    "and so on !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for words, tag in blob.tags:\n",
    "    print (words, tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis\n",
    "\n",
    "Sentiment analysis is basically the process of determining the attitude or the emotion of the writer, i.e., whether it is positive or negative or neutral.\n",
    "\n",
    "The sentiment function of textblob returns two properties, polarity, and subjectivity.\n",
    "\n",
    "Polarity is float which lies in the range of [-1,1] where 1 means positive statement and -1 means a negative statement. \n",
    "\n",
    "Subjective sentences generally refer to personal opinion, emotion or judgment whereas objective refers to factual information. Subjectivity is also a float which lies in the range of [0,1] , 0 being ideally objective and 1 being extremely subjective.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (blob,'\\n')\n",
    "print(blob.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A few examples !\n",
    "\n",
    "neg1=TextBlob(\"It is such a sad , gloomy day today.\")\n",
    "obj1=TextBlob(\"The sun rises in the east and sets in the west.\")\n",
    "neg2=TextBlob(\"The Supreme court came down heavily on the government over its ineffective policies.\")\n",
    "print(neg1)\n",
    "print(neg1.sentiment,'\\n')\n",
    "print(obj1)\n",
    "print(obj1.sentiment,'\\n')\n",
    "print(neg2)\n",
    "print(neg2.sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Inflection and Lemmatization\n",
    "\n",
    "Inflection is a process of word formation in which characters are added to the base form of a word to express grammatical meanings. Word inflection in TextBlob is very simple, i.e., the words we tokenized from a textblob can be easily changed into singular or plural."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (blob.sentences[1].words[7])\n",
    "print (blob.sentences[1].words[7].pluralize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import Word\n",
    "w = Word('Platform')\n",
    "w.pluralize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## using tags\n",
    "for word,pos in blob.tags:\n",
    "    if pos == 'NNP':\n",
    "        print (word.pluralize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatization usually refers to doing things properly with the use of a vocabulary and morphological analysis of words, normally aiming to remove inflectional endings only and to return the base or dictionary form of a word, which is known as the lemma ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## lemmatization\n",
    "\n",
    "w1 = Word('running')\n",
    "print(w1.lemmatize(\"v\"))  ## v here represents verb\n",
    "w2= Word('breaking')\n",
    "print(w2.lemmatize('v'))\n",
    "w3= Word('cacti')\n",
    "print(w3.lemmatize('n'))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ngrams\n",
    "\n",
    "A combination of multiple words together are called N-Grams. N grams (N > 1) are generally more informative as compared to words, and can be used as features for language modelling.  N-grams can be easily accessed in TextBlob using the ngrams function, which returns a tuple of n successive words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ngram in blob.ngrams(3):\n",
    "    print (ngram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spelling correction\n",
    "\n",
    "Spelling correction is a cool feature which TextBlob offers, we can be accessed using the correct function as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can check the spellings for 'Word' objects-\n",
    "w=Word('aprentise')\n",
    "w.spellcheck()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#However , for correcting entire sentences or even paragraphs and articles, we use correct() function,an attribute of TextBlob\n",
    "wrong=TextBlob(\"The incambant govurnment is epxected to win a thamping majorly\")\n",
    "wrong.correct()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong.words[8].spellcheck()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a short summary from a text\n",
    "\n",
    "This is a simple trick which we will be using the things we learned above. First, take a look at the code shown below and to understand yourself.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "summ = TextBlob('The effects of technological advancement are both positive and negative.\\n\\\n",
    "Positively, technology advancement has simplified the way we do things, it saves time, it increases on production,\\\n",
    "it simplifies communication, it has improved health care and it has also improved our educational environment.\\n\\\n",
    "Negatively , technology advancement has made humans so lazy , technology users are so dependent on new advance tech tools ,\\\n",
    "this laziness has resulted into less innovation , it has increased on health risks because technology users exercise less \\\n",
    ", it has affected the environment because of the increase pollution which has affected the Ozone layers which has resulted \\\n",
    "into global warming. When it comes to education, students are more dependent on Calculators and \\\n",
    "computers to solve simple equations; in this case they can not train their brains to solve a simple task which makes them \\\n",
    "lame in class.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nouns = list()\n",
    "for word, tag in summ.tags:\n",
    "    if tag == 'NN':\n",
    "        nouns.append(word.lemmatize())\n",
    "\n",
    "#Removing duplicates - \n",
    "nouns=set(nouns)\n",
    "nouns=list(nouns)\n",
    "       \n",
    "\n",
    "print (\"This text is about...\")\n",
    "for item in nouns:\n",
    "    word = Word(item)\n",
    "    print (word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans1 = TextBlob('I find this feature to be extremely useful.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://cloud.google.com/translate/docs/languages\n",
    "# trans1.translate(to ='kn')\n",
    "trans1.translate(to ='hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans2 = TextBlob('هذه هي أداة عظيمة للاستخدام')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans2.detect_language()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans2.translate(from_lang='ar', to ='en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even if you don’t explicitly define the source language, TextBlob will automatically detect the language and translate into the desired language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans2.translate(to= 'en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Classification using textblob\n",
    "Textblob provides in-build classifiers module to create a custom classifier. So, let’s quickly import it and create a basic classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [\n",
    "     ('The sandwich is bad', 'neg'),\n",
    "     ('there is a good place near my home', 'pos'),\n",
    "     ('I feel very good about these beers.', 'pos'),\n",
    "     ('this is bad work on my part.', 'neg'),\n",
    "     (\"The view is good\", 'pos'),\n",
    "     ('This restaurant serves bad food', 'neg'),\n",
    "     ('She has a bad mood today', 'neg'),\n",
    "     (\"I love how she smiles at me\", 'pos'),\n",
    "     ('he is destroying my project', 'neg'),\n",
    "     ('Her boss is horrible', 'neg'),\n",
    "     ('Parul hates wasting her time','neg'),\n",
    "     ('I am in love with this place','pos'),\n",
    "     ('It was bad on his part to not help her in need','neg'),\n",
    "     ('It feels so good to have you around','pos'),\n",
    "     ('the perfume had a lovely smell','pos')\n",
    " ]\n",
    "test = [\n",
    "     ('the beer was good.', 'pos'),\n",
    "     ('I am bad at my job', 'neg'),\n",
    "     (\"I am feeling lovely today.\", 'pos'),\n",
    "     (\"I feel good\", 'pos'),\n",
    "     ('Gary is a good friend of mine.', 'pos'),\n",
    "     (\"I can't believe I'm this bad.\", 'neg')\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import classifiers\n",
    "\n",
    "classifier = classifiers.NaiveBayesClassifier(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that here we have used Naive Bayes classifier, but TextBlob also offers Decision tree classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (classifier.accuracy(test))\n",
    "classifier.show_informative_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check1 = TextBlob('I love this weather', classifier=classifier)\n",
    "print (check1,'-',check1.classify())\n",
    "check2 = TextBlob('The food is horrible', classifier=classifier)\n",
    "print (check2,'-',check2.classify())\n",
    "check3 = TextBlob('He is good at Data science', classifier=classifier)\n",
    "print (check3,'-',check3.classify())\n",
    "check4 = TextBlob('She is having a bad day', classifier=classifier)\n",
    "print (check4,'-',check4.classify())\n",
    "check5 = TextBlob('I found the place lovely', classifier=classifier)\n",
    "print (check5,'-',check5.classify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The nltk library has a pre-trained movie reviews classifiers , which can be used to judge the review of a movie to be positive or negative\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Consider the following text - \n",
    "\n",
    "para=TextBlob('India has one of the most rapidly groving service sectors in the world with an anual growth rate above \\\n",
    "9% since 2001, which contribeted to 57% of GDP in 2012–13. India has becone a major exporting country of Information \\\n",
    "Technology sevrices, Businass Process Oubsourcing (BPO) services, and software services with $154 billion revenue in 2017.\\\n",
    " The Information Technology industry condinues to be the largest priwate-sector emplofer in India. India is the second-largest\\\n",
    " start-up centre in the world with over 3,100 tecknology start-ups in 2018–19.The agricutlural sector is the largst employer \\\n",
    " in India\\'s economy but contributes to a declining share of its GDP (17% in 2013–14). India ranks second worldwide in farm \\\n",
    " output. The industry (manufacturing) sector has held a steady share of its econogic contribution (26% of GDP in 2013–14).\\\n",
    " The Indian automodite industry is one of the largest in the world with an agnual production of 21.48 million vehicles \\\n",
    " (mostly two and three-wheelers) in 2013–14. India had $600 bilion worth of retail market in 2015 and one of world\\'s \\\n",
    " quikest growing e-commerse margets.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First of all, check the spellings and correct any misspellings\n",
    "para_new=None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find out all the sentences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find out the number of adverbs in this paragraph ( tag=RB)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find out the main topic of this paragraph ( Hint - use the nouns, tag=NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find out the sentiment and the subjectivity of the entire paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find out the sentiment and the subjectivity of each sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print the singular proper nouns to uppercase for the para ( tag=NNP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Translate the entire paragraph to Hindi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hindi=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SOLUTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Consider the following text - \n",
    "\n",
    "para=TextBlob('India has one of the most rapidly groving service sectors in the world with an anual growth rate above \\\n",
    "9% since 2001, which contribeted to 57% of GDP in 2012–13. India has becone a major exporting country of Information \\\n",
    "Technology sevrices, Businass Process Outsourcing (BPO) services, and software services with $154 billion revenue in 2017.\\\n",
    " The Information Technology industry condinues to be the largest priwate-sector emplofer in India. India is the second-largest\\\n",
    " start-up centre in the world with over 3,100 tecknology start-ups in 2018–19.The agricutlural sector is the largst employer \\\n",
    " in India\\'s economy but contributes to a declining share of its GDP (17% in 2013–14). India ranks second worldwide in farm \\\n",
    " output. The industry (manufacturing) sector has held a steady share of its econogic contribution (26% of GDP in 2013–14).\\\n",
    " The Indian automodite industry is one of the largest in the world with an agnual production of 21.48 million vehicles \\\n",
    " (mostly two and three-wheelers) in 2013–14. India had $600 bilion worth of retail market in 2015 and one of world\\'s \\\n",
    " quikest growing e-commerse margets.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First of all, check the spellings and correct any misspellings\n",
    "para_new=para.correct()\n",
    "para_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find out all the sentences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "para_new.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find out the number of adverbs in this paragraph ( tag=RB)\n",
    "j=0\n",
    "for word,tag in para_new.tags:\n",
    "    if tag == 'RB':\n",
    "        j=j+1\n",
    "print(j)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find out the main topic of this paragraph ( Hint - use the nouns, tag=NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nouns2 = list()\n",
    "for word, tag in para_new.tags:\n",
    "    if tag == 'NNP':\n",
    "        nouns2.append(word.lemmatize())\n",
    "\n",
    "#Removing duplicates - \n",
    "nouns2=set(nouns2)\n",
    "nouns2=list(nouns2)\n",
    "       \n",
    "\n",
    "print (\"This text is about...\")\n",
    "for item in nouns2:\n",
    "    word = Word(item)\n",
    "    print (word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find out the sentiment and the subjectivity of the entire paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(para_new.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find out the sentiment and the subjectivity of each sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,sentence in enumerate(para_new.sentences):\n",
    "        print('Sentence-',i+1,sentence.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print the singular proper nouns to uppercase for the para ( tag=NNP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word,tag in para_new.tags:\n",
    "    if tag == 'NNP':\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hindi the entire paragraph to Hindi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hindi=para_new.translate(to= 'hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hindi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
