{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## # Direct usage of y values instead of one hot encoding.\n",
    "\n",
    "Instead of providing a 1-hot-encoding of the y values during training (loos function required is categorical_crossentropy),\n",
    "the y values can be directly used (loss function should be sparse_categorical_crossentropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import pickle\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.datasets import fetch_mldata\n",
    "#mnist = fetch_mldata('MNIST original')\n",
    "#mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "#Alternate method of loading data - approx time 37s\n",
    "\n",
    "X=np.loadtxt('../../Data/X.txt')\n",
    "y=np.loadtxt('../../Data/y.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((70000, 784), (70000,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X, y = mnist[\"data\"], mnist[\"target\"]\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=y.reshape(70000,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]\n",
    "shuffle_index = np.random.permutation(60000)\n",
    "X_train, y_train = X_train[shuffle_index], y_train[shuffle_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (60000, 1))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\subhrajit\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Initialising the ANN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "#classifier.add(Dense(output_dim = 6, init = 'uniform', activation = 'relu', input_dim = 11))\n",
    "classifier.add(Dense(activation=\"relu\", input_dim=784, units=300, kernel_initializer=\"uniform\"))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "#classifier.add(Dense(output_dim = 6, init = 'uniform', activation = 'relu'))\n",
    "classifier.add(Dense(activation=\"relu\", units=16, kernel_initializer=\"uniform\"))\n",
    "\n",
    "# Adding the third hidden layer\n",
    "#classifier.add(Dense(output_dim = 6, init = 'uniform', activation = 'relu'))\n",
    "classifier.add(Dense(activation=\"relu\", units=16, kernel_initializer=\"uniform\"))\n",
    "\n",
    "# Adding the output layer\n",
    "#classifier.add(Dense(output_dim = 1, init = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "classifier.add(Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the ANN\n",
    "#classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_5 = (y_train == 5)\n",
    "y_test_5 = (y_test == 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55587</th>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55877</th>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16468</th>\n",
       "      <td>9.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55395</th>\n",
       "      <td>6.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13672</th>\n",
       "      <td>4.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34616</th>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7389</th>\n",
       "      <td>8.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51257</th>\n",
       "      <td>3.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37536</th>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55343</th>\n",
       "      <td>3.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0      1\n",
       "55587  2.0  False\n",
       "55877  1.0  False\n",
       "16468  9.0  False\n",
       "55395  6.0  False\n",
       "13672  4.0  False\n",
       "34616  0.0  False\n",
       "7389   8.0  False\n",
       "51257  3.0  False\n",
       "37536  2.0  False\n",
       "55343  3.0  False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([pd.Series(y_train.ravel()), pd.Series(y_train_5.ravel())], axis=1).sample(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\subhrajit\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.0924 - acc: 0.9707\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.0231 - acc: 0.9925\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.0151 - acc: 0.9950\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.0102 - acc: 0.9968\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.0070 - acc: 0.9977\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0064 - acc: 0.9980\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0048 - acc: 0.9986\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0041 - acc: 0.9987\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0027 - acc: 0.9993\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.0021 - acc: 0.9994\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.0025 - acc: 0.9992\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.0024 - acc: 0.9993\n",
      "Model Saved in file  oneclass.sav\n"
     ]
    }
   ],
   "source": [
    "filename = 'oneclass.sav'\n",
    "try:\n",
    "    classifier = pickle.load(open(filename, 'rb'))\n",
    "    print('Classifier Loaded from file')\n",
    "except:\n",
    "    classifier.fit(X_train, y_train_5, batch_size = 128, epochs = 12)\n",
    "    pickle.dump(classifier, open(filename, 'wb'))\n",
    "    print('Model Saved in file ',filename )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0026 - acc: 0.9992\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0018 - acc: 0.9995\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.0012 - acc: 0.9997\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.0013 - acc: 0.9996\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.0030 - acc: 0.9992\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0021 - acc: 0.9994\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0021 - acc: 0.9995\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.0010 - acc: 0.9998\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 5.6856e-04 - acc: 0.9999\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.0015 - acc: 0.9996\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.0020 - acc: 0.9994\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.0018 - acc: 0.9997\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cf885addd8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Manual Fitting the ANN to the Training set\n",
    "\n",
    "classifier.fit(X_train, y_train_5,  batch_size = 128, epochs = 12)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Expected Output \n",
    "-----------------\n",
    "Epoch 1/12\n",
    "60000/60000 [==============================] - 8s 139us/step - loss: 0.0922 - acc: 0.9708\n",
    "Epoch 2/12\n",
    "60000/60000 [==============================] - 8s 130us/step - loss: 0.0222 - acc: 0.9928\n",
    "Epoch 3/12\n",
    "60000/60000 [==============================] - 7s 120us/step - loss: 0.0146 - acc: 0.9953\n",
    "Epoch 4/12\n",
    "60000/60000 [==============================] - 7s 124us/step - loss: 0.0095 - acc: 0.9970\n",
    "Epoch 5/12\n",
    "60000/60000 [==============================] - 7s 116us/step - loss: 0.0074 - acc: 0.9976\n",
    "Epoch 6/12\n",
    "60000/60000 [==============================] - 7s 115us/step - loss: 0.0057 - acc: 0.9979\n",
    "Epoch 7/12\n",
    "60000/60000 [==============================] - 7s 121us/step - loss: 0.0040 - acc: 0.9987\n",
    "Epoch 8/12\n",
    "60000/60000 [==============================] - 7s 121us/step - loss: 0.0045 - acc: 0.9985\n",
    "Epoch 9/12\n",
    "60000/60000 [==============================] - 8s 132us/step - loss: 0.0031 - acc: 0.9992\n",
    "Epoch 10/12\n",
    "60000/60000 [==============================] - 8s 128us/step - loss: 0.0022 - acc: 0.9993\n",
    "Epoch 11/12\n",
    "60000/60000 [==============================] - 8s 129us/step - loss: 0.0016 - acc: 0.9995\n",
    "Epoch 12/12\n",
    "60000/60000 [==============================] - 7s 117us/step - loss: 0.0013 - acc: 0.9996"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test_5, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9089,   19],\n",
       "       [  31,  861]], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TN= 9089 TP= 861 FN= 31 FP= 19\n"
     ]
    }
   ],
   "source": [
    "# Assigning Variables for convinience\n",
    "TN = cm[0][0]\n",
    "FP = cm[0][1]\n",
    "FN = cm[1][0]\n",
    "TP = cm[1][1]\n",
    "print(\"TN=\",TN, \"TP=\",TP, \"FN=\",FN,\"FP=\",FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  1.0\n",
      "Sensitivity or recall(5 Predictions): 0.97\n",
      "specificity(not 5 predictions) 1.0\n"
     ]
    }
   ],
   "source": [
    "# acc=(TP+TN)/(TP+TN+FP+FN)\n",
    "# print ('Accuracy ', acc)\n",
    "\n",
    "accuracy = (TP+TN) / float(TP+TN+FN +FP)\n",
    "print('Accuracy ', round(accuracy, 2))\n",
    "\n",
    "sensitivity = TP / float(FN + TP)\n",
    "print('Sensitivity or recall(5 Predictions):',round(sensitivity, 2))\n",
    "\n",
    "specificity = TN / (TN + FP)\n",
    "print('specificity(not 5 predictions)',round(specificity,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observation :  Our sensitivity is 97% - compare to  94% for RandomForestclassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Class Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]\n",
    "shuffle_index = np.random.permutation(60000)\n",
    "X_train, y_train = X_train[shuffle_index], y_train[shuffle_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (60000, 1))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the ANN\n",
    "classifier_mc = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "#classifier.add(Dense(output_dim = 6, init = 'uniform', activation = 'relu', input_dim = 11))\n",
    "classifier_mc.add(Dense(activation=\"relu\", input_dim=784, units=300, kernel_initializer=\"uniform\"))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "#classifier.add(Dense(output_dim = 6, init = 'uniform', activation = 'relu'))\n",
    "classifier_mc.add(Dense(activation=\"relu\", units=16, kernel_initializer=\"uniform\"))\n",
    "\n",
    "# Adding the third hidden layer\n",
    "#classifier.add(Dense(output_dim = 6, init = 'uniform', activation = 'relu'))\n",
    "classifier_mc.add(Dense(activation=\"relu\", units=16, kernel_initializer=\"uniform\"))\n",
    "\n",
    "# Adding the output layer\n",
    "#classifier.add(Dense(output_dim = 1, init = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "classifier_mc.add(Dense(activation=\"softmax\", units=10, kernel_initializer=\"uniform\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the ANN\n",
    "# classifier_mc.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "classifier_mc.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# encode class values as integers\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train)\n",
    "encoded_Y = encoder.transform(y_train)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "y_train = np_utils.to_categorical(encoded_Y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_full = np.zeros((y_train.shape[0], 10), dtype=np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.astype(int).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in y_train:\n",
    "    y_train_full[i, y_train[i]] = y_train[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 2, 6, 2, 0, 1, 2, 9])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 2, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 6, 0, 0, 0],\n",
       "       [0, 0, 2, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 2, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 9]], dtype=int8)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_full[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Loaded\n"
     ]
    }
   ],
   "source": [
    "filename = 'multiclass.sav'\n",
    "try:\n",
    "    classifier_mc = pickle.load(open(filename, 'rb'))\n",
    "    print('Model Loaded')\n",
    "except:\n",
    "    classifier_mc.fit(X_train, y_train, batch_size = 128, epochs = 12)\n",
    "    pickle.dump(classifier_mc, open(filename, 'wb'))\n",
    "    print('Model Saved in file ',filename )"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "EXPECTED OUTPUT\n",
    "------------------\n",
    "Epoch 1/12\n",
    "60000/60000 [==============================] - 8s 129us/step - loss: 0.0227 - acc: 0.9950\n",
    "Epoch 2/12\n",
    "60000/60000 [==============================] - 8s 137us/step - loss: 0.0137 - acc: 0.9974\n",
    "Epoch 3/12\n",
    "60000/60000 [==============================] - 9s 145us/step - loss: 0.0123 - acc: 0.9981\n",
    "Epoch 4/12\n",
    "60000/60000 [==============================] - 7s 118us/step - loss: 0.0110 - acc: 0.9986\n",
    "Epoch 5/12\n",
    "60000/60000 [==============================] - 8s 129us/step - loss: 0.0097 - acc: 0.9989\n",
    "Epoch 6/12\n",
    "60000/60000 [==============================] - 7s 116us/step - loss: 0.0094 - acc: 0.9990\n",
    "Epoch 7/12\n",
    "60000/60000 [==============================] - 7s 119us/step - loss: 0.0091 - acc: 0.9991\n",
    "Epoch 8/12\n",
    "60000/60000 [==============================] - 7s 122us/step - loss: 0.0086 - acc: 0.9991\n",
    "Epoch 9/12\n",
    "60000/60000 [==============================] - 7s 119us/step - loss: 0.0115 - acc: 0.9984\n",
    "Epoch 10/12\n",
    "60000/60000 [==============================] - 8s 127us/step - loss: 0.0157 - acc: 0.9971\n",
    "Epoch 11/12\n",
    "60000/60000 [==============================] - 7s 124us/step - loss: 0.0131 - acc: 0.9978\n",
    "Epoch 12/12\n",
    "60000/60000 [==============================] - 8s 127us/step - loss: 0.0159 - acc: 0.9973"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_mc=classifier_mc.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 9, 9, 9], dtype=int64)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_mc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = confusion_matrix(y_test, y_pred_mc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 964,    1,    2,    1,    1,    5,    4,    0,    1,    1],\n",
       "       [   0, 1124,    2,    2,    0,    1,    1,    0,    5,    0],\n",
       "       [   1,    2, 1010,    7,    0,    2,    4,    1,    5,    0],\n",
       "       [   0,    0,    4,  992,    0,    4,    0,    2,    6,    2],\n",
       "       [   0,    0,    2,    0,  954,    0,   13,    1,    2,   10],\n",
       "       [   1,    0,    0,    8,    1,  872,    4,    1,    5,    0],\n",
       "       [   3,    3,    2,    0,    2,    7,  939,    0,    2,    0],\n",
       "       [   0,    6,   19,    5,    0,    0,    0,  988,    2,    8],\n",
       "       [   3,    1,    2,    1,    1,    6,    3,    1,  951,    5],\n",
       "       [   1,    2,    0,   13,   13,   10,    2,    5,    7,  956]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  97.5\n"
     ]
    }
   ],
   "source": [
    "ok=0\n",
    "for i in range(0,10):\n",
    "    ok=ok+matrix[i,i]\n",
    "\n",
    "print('Accuracy ', 100*ok/matrix.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.98      0.99      0.99       980\n",
      "        1.0       0.99      0.99      0.99      1135\n",
      "        2.0       0.97      0.97      0.97      1032\n",
      "        3.0       0.97      0.98      0.97      1010\n",
      "        4.0       0.98      0.97      0.98       982\n",
      "        5.0       0.98      0.97      0.97       892\n",
      "        6.0       0.98      0.98      0.98       958\n",
      "        7.0       0.97      0.97      0.97      1028\n",
      "        8.0       0.98      0.97      0.97       974\n",
      "        9.0       0.97      0.97      0.97      1009\n",
      "\n",
      "avg / total       0.98      0.98      0.98     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Getting classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,y_pred_mc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation :  Our Recall, Precision, F1 is 98% - compare to 95% in RandomForestclassifier "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    " Multiclass - Random Forest\n",
    " \n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "        0.0       0.95      0.99      0.97       980\n",
    "        1.0       0.97      0.99      0.98      1135\n",
    "        2.0       0.93      0.95      0.94      1032\n",
    "        3.0       0.92      0.93      0.92      1010\n",
    "        4.0       0.93      0.95      0.94       982\n",
    "        5.0       0.94      0.92      0.93       892\n",
    "        6.0       0.96      0.96      0.96       958\n",
    "        7.0       0.97      0.93      0.95      1028\n",
    "        8.0       0.93      0.91      0.92       974\n",
    "        9.0       0.94      0.92      0.93      1009\n",
    "\n",
    "avg / total       0.95      0.95      0.95     10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
