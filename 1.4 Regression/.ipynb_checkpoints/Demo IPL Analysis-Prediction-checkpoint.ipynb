{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import Lars\n",
    "from sklearn.linear_model import LassoLars\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.linear_model import PassiveAggressiveRegressor\n",
    "\n",
    "# Robust regression is interested in fitting a regression model in the presence of corrupt data: \n",
    "# either outliers, or error in the model.\n",
    "# Scikit-learn provides 3 robust regression estimators: RANSAC, Theil Sen and HuberRegressor\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "from sklearn.linear_model import RANSACRegressor\n",
    "from sklearn.linear_model import TheilSenRegressor\n",
    "\n",
    "# TO BE WORKED ON : Polynomial regression: extending linear models with basis functions\n",
    "\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.svm import NuSVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import ExtraTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "#from xgboost.sklearn import XGBRegressor\n",
    "#from lightgbm import LGBMRegressor\n",
    "#from catboost import CatBoostRegressor\n",
    "\n",
    "from sklearn.neighbors.nearest_centroid import NearestCentroid\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "from math import sqrt\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, learning_curve\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRegressors():\n",
    "    Regressors = []\n",
    "    RegList=[]\n",
    "    # 0\n",
    "    Linear = LinearRegression()\n",
    "    Regressors.append(Linear)\n",
    "    RegList.append('Linear')\n",
    "\n",
    "    #XGBR = XGBRegressor()\n",
    "    #Regressors.append(XGBR)\n",
    "\n",
    "    # 1\n",
    "    RandomForest = RandomForestRegressor(max_depth=3,min_samples_leaf=10, min_samples_split=15,\n",
    "     n_estimators=50)\n",
    "    Regressors.append(RandomForest)\n",
    "    RegList.append('RF')\n",
    "\n",
    "    # 11\n",
    "    #LGBMR = LGBMRegressor()\n",
    "    #Regressors.append(LGBMR)\n",
    "\n",
    "\n",
    "    # 2\n",
    "    ExtraTrees = ExtraTreesRegressor(n_estimators=10,min_samples_leaf=10, min_samples_split=10, random_state=0)\n",
    "    Regressors.append(ExtraTrees)\n",
    "    RegList.append('ExtraTrees')\n",
    "\n",
    "    # 3\n",
    "    GradientBoosting = GradientBoostingRegressor()\n",
    "    Regressors.append(GradientBoosting)\n",
    "    RegList.append('GradBoost')\n",
    "\n",
    "    # 1\n",
    "    #lars=Lars()\n",
    "    #Regressors.append(lars)\n",
    "\n",
    "    # 4\n",
    "    lasso = Lasso()\n",
    "    Regressors.append(lasso)\n",
    "    RegList.append('Lasso')\n",
    "\n",
    "    # 5\n",
    "    elasticNet = ElasticNet()\n",
    "    Regressors.append(elasticNet)\n",
    "    RegList.append('E-net')\n",
    "\n",
    "    # 6\n",
    "    ridge = Ridge()\n",
    "    Regressors.append(ridge)\n",
    "    RegList.append('Ridge')\n",
    "\n",
    "    #CatBoost = CatBoostRegressor(verbose=0)\n",
    "    #Regressors.append(CatBoost)\n",
    "\n",
    "  \n",
    "\n",
    "    # 7\n",
    "    AdaBoost = AdaBoostRegressor()\n",
    "    Regressors.append(AdaBoost)\n",
    "    RegList.append('Adaboost')\n",
    " \n",
    "    # 8\n",
    "    KNeighbors = KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
    "          metric_params=None, n_jobs=1, n_neighbors=10, p=2,\n",
    "          weights='uniform')\n",
    "    Regressors.append(KNeighbors)\n",
    "    RegList.append('KNN')\n",
    "\n",
    "    # 25\n",
    "    #SGD = SGDRegressor()\n",
    "    #Regressors.append(SGD)\n",
    "\n",
    "  \n",
    "    return Regressors,RegList\n",
    "\n",
    "def predictAll(Regressors, X_train, y_train, X_test,y_test,RegList):\n",
    "\n",
    "    predictions=[]\n",
    "    cvscores=[]\n",
    "    models =[]\n",
    "    fitted_model=[]\n",
    "    y_train= y_train.ravel()\n",
    "    for regressor in Regressors:\n",
    "        model_name = type(regressor).__name__\n",
    "        models.append(model_name)\n",
    "        print(' Model', model_name)\n",
    "        regressor.fit(X_train,y_train)\n",
    "        fitted_model.append(regressor)\n",
    "        prediction = regressor.predict(X_test)\n",
    "        predictions.append(np.round(prediction))\n",
    "\n",
    "        score = cross_val_score(regressor,X_train, y_train,cv=5,scoring=\"neg_mean_squared_error\")\n",
    "        meanscore=score.mean()\n",
    "        cvscores.append(np.sqrt(-meanscore))\n",
    "        #print('CV Score',score,meanscore, np.sqrt(-meanscore))\n",
    "    \n",
    "    RMS=[]\n",
    "    R2=[]\n",
    "    scr=pd.DataFrame( columns = RegList)\n",
    "    i=0\n",
    "    for prediction in predictions:\n",
    "        msscore = mean_squared_error(y_test, prediction)\n",
    "        r2=r2_score(y_test, prediction)\n",
    "        rms = sqrt(msscore)\n",
    "        RMS.append(rms)\n",
    "        R2.append(r2)\n",
    "        scr.iloc[:,i]=np.round(prediction,0)\n",
    "        i=i+1\n",
    "\n",
    "    #scr.index=X_test.ravel()\n",
    "    scr=scr.sort_index()\n",
    "\n",
    "    compare = pd.DataFrame(list(zip(models,RMS,R2,cvscores)), columns=['Model','RMS','R2','CV'])\n",
    "    return scr, fitted_model, compare.sort_values(by='RMS')\n",
    "\n",
    "#Display the table of predictions\n",
    "def display_result_runs(models, Reglist):\n",
    "    \n",
    "    idx = np.array(range(100,145, 5))\n",
    "    i=0    \n",
    "    scr=pd.DataFrame( columns = Reglist)\n",
    "    for model in models:\n",
    "\n",
    "        p= model.predict(idx.reshape(-1, 1))\n",
    "        #print(score,round(p[0][0]))\n",
    "        scr.iloc[:,i]=np.round(p)\n",
    "        i=i+1\n",
    "\n",
    "    scr.index=idx\n",
    "\n",
    "    #result = pd.DataFrame(table, columns=['SCORE','PRED'])\n",
    "    return scr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data of IPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matchdata=pd.read_csv('/Data/match_scores.csv',index_col=0)\n",
    "matchdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matchdata.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matchdata.Innings_No.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### innings 3 and 4 are superovers - avoid ininings 2 too and pick innings which have played full\n",
    "matchdata=matchdata[(matchdata['Innings_No']==1) | (matchdata['Innings_No']==2) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Innings 1 and 2 Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(1,2,figsize=(12,4))\n",
    "ax0=ax[0]\n",
    "ax1=ax[1]\n",
    "\n",
    "# all matches which have gone till 20th over \n",
    "\n",
    "cond = (matchdata['Ball_id_15']>=90 ) & (matchdata['Ball_id_20']>=115)\n",
    "data = matchdata[cond]\n",
    "\n",
    "data=matchdata[(matchdata['Innings_No']==1)]\n",
    "no_of_innings = data.shape[0]\n",
    "\n",
    "sns.scatterplot(x='RUNS_15',y='RUNS_20', data=matchdata[(matchdata['Innings_No']==1)],  ax=ax0)\n",
    "ax0.set_title('Innings 1 # Matches '+str(no_of_innings))\n",
    "\n",
    "\n",
    "data=matchdata[(matchdata['Innings_No']==2)]\n",
    "no_of_innings = data.shape[0]\n",
    "\n",
    "sns.scatterplot(x='RUNS_15',y='RUNS_20', data=matchdata[(matchdata['Innings_No']==2)], color='r', ax=ax1)\n",
    "ax1.set_title('Innings 2 # Matches '+str(no_of_innings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(1,2,figsize=(12,4))\n",
    "\n",
    "cond = (matchdata['Innings_No']==1) & (matchdata['Ball_id_15']>=90 ) & (matchdata['Ball_id_20']>=115)\n",
    "data=matchdata[cond]\n",
    "\n",
    "sns.distplot(data['RUNS_15'], color='b', label='15 overs', ax=ax[0])\n",
    "\n",
    "cond = (matchdata['Innings_No']==1) & (matchdata['Ball_id_15']>=90 ) & (matchdata['Ball_id_20']>=115)\n",
    "sns.distplot(data['RUNS_20'], color='r', label='20 overs', ax=ax[0])\n",
    "ax[0].set_title ('Innings 1 - Score Distribution : 15 and 20 overs')\n",
    "\n",
    "ax[0].legend()\n",
    "\n",
    "## Innings 2\n",
    "\n",
    "cond = (matchdata['Innings_No']==2) & (matchdata['Ball_id_15']>=90 ) & (matchdata['Ball_id_20']>=115)\n",
    "data=matchdata[cond]\n",
    "\n",
    "sns.distplot(data['RUNS_15'], color='b', label='15 overs', ax=ax[1])\n",
    "\n",
    "cond = (matchdata['Innings_No']==2) & (matchdata['Ball_id_15']>=90 ) & (matchdata['Ball_id_20']>=115)\n",
    "sns.distplot(data['RUNS_20'], color='r', label='20 overs', ax=ax[1])\n",
    "ax[1].legend()\n",
    "\n",
    "ax[1].set_title ('Innings 2 - Score Distribution : 15 and 20 overs')\n",
    "\n",
    "ax[0].legend()\n",
    "\n",
    "\n",
    "plt.show()\n",
    "#sns.barplot(data = data, y='RUNS_15', x='Innings_No',palette='Paired_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overlayed Scatter\n",
    "cond = (matchdata['Innings_No']>=1) & (matchdata['Innings_No']<=2) & (matchdata['Ball_id_15']>=90 ) & (matchdata['Ball_id_20']>=115)\n",
    "data = matchdata[cond]\n",
    "sns.scatterplot(x='RUNS_15',y='RUNS_20', data=data, hue='Innings_No')\n",
    "plt.title('Innings 1 and 2 Scores - Overlayed')\n",
    "plt.legend(bbox_to_anchor=(1.1, 1.05))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check out the distribution of scores of  first Innings Only - Scatter Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(figsize=(12,6))\n",
    "sns.set_style('white')\n",
    "\n",
    "cond = (matchdata['Innings_No']==1) &  (matchdata['Ball_id_15']>=90 ) & (matchdata['Ball_id_20']>=115)\n",
    "data = matchdata[cond]\n",
    "\n",
    "\n",
    "sns.scatterplot(x='RUNS_15',y='RUNS_20', data=data, ax=ax)\n",
    "no_of_innings = data.shape[0]\n",
    "ax.set(title ='All IPL Matches ( 1st Inninings) - No of Innings : '+str(no_of_innings))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check out the distribution of scores after 20 overs - Distribution Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Check out the distribution of scores - Scatter Plot\n",
    "\n",
    "cond = (matchdata['Innings_No']==1) &  (matchdata['Ball_id_15']>=90 ) & (matchdata['Ball_id_20']>=115)\n",
    "data = matchdata[cond]\n",
    "\n",
    "\n",
    "sns.distplot(data['RUNS_20'], kde=False)\n",
    "\n",
    "Avg=np.round(data['RUNS_20'].median(),2)\n",
    "\n",
    "xp=[Avg]*10\n",
    "yp=list(range(0,100,10))\n",
    "plt.plot(xp, yp, linewidth=3, color='r', ls='-', label='Median:'+str(Avg))\n",
    "\n",
    "plt.title('First Innings Final Scores After 20 Overs: Median ' +str(Avg))\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a multiplier feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matchdata['Mult']= matchdata ['RUNS_20']/matchdata['RUNS_15']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond = (matchdata['Innings_No']==1) &  (matchdata['Ball_id_15']>=90 ) & (matchdata['Ball_id_20']>=115)\n",
    "data = matchdata[cond]\n",
    "\n",
    "sns.distplot(data['Mult'], kde=False)\n",
    "\n",
    "Avg=np.round(data['Mult'].median(),2)\n",
    "\n",
    "xp=[Avg]*10\n",
    "yp=list(range(0,100,10))\n",
    "plt.plot(xp, yp, linewidth=3, color='r', ls='-', label='Median:'+str(Avg))\n",
    "\n",
    "plt.title(' Acceleration Between 15 to 20 Overs: Median ' +str(Avg))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation: Teams multiply their score by 1.2x to 1.8x with a median around 1.44x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Model 1:   Predict Score of Over 20 Based on Score of Over 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data set head\n",
    "cond = (matchdata['Innings_No']==1) & (matchdata['Ball_id_15']>=90 ) & (matchdata['Ball_id_20']>=120 )\n",
    "matchdata[cond].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load X and y\n",
    "cond = (matchdata['Innings_No']==1) & (matchdata['Ball_id_15']>=90 ) & (matchdata['Ball_id_20']>=120 )\n",
    "# Load the features to a variable X\n",
    "X = matchdata[cond][['RUNS_15']]\n",
    "\n",
    "# Load the dependent variable to y\n",
    "y = matchdata[cond]['RUNS_20']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets Build a Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "lr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.coef_ , lr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs=200\n",
    "lr.predict([[runs]])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lr.predict(X_test)\n",
    "\n",
    "predictions[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "# Let's create an instance for the LinerRegression model\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1)\n",
    "\n",
    "lr = linear_model.LinearRegression()\n",
    "\n",
    "# Training the model on our train dataset\n",
    "lr.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "\n",
    "# Getting predictions from the model \n",
    "#X_test=X_test.values.reshape(-1,1)\n",
    "\n",
    "predictions = lr.predict(X_test)\n",
    "\n",
    "from sklearn import metrics\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, predictions))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, predictions))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions)))\n",
    "print('R2:', metrics.r2_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What will be the predicted score at 100 runs in 15 overs?\n",
    "\n",
    "runs=100\n",
    "lr.predict([[runs]])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot the Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do a prediction for 15th over score in a range of 60 to 200\n",
    "xx=[]\n",
    "yy=[]\n",
    "for runs in range (60,200,5):\n",
    "    scr = np.round(lr.predict([[runs]])[0])\n",
    "    #print(runs, scr)\n",
    "    xx.append(runs)\n",
    "    yy.append(scr)\n",
    "    \n",
    "    \n",
    "cond = (matchdata['Innings_No']==1) & (matchdata['Ball_id_15']>=90 ) & (matchdata['Ball_id_20']>=120 )\n",
    "data = matchdata[cond]\n",
    "# plot the actual \n",
    "plt.scatter(data['RUNS_15'],data['RUNS_20'])\n",
    "plt.plot(xx, yy, c='r', lw=3)\n",
    "plt.title('Linear Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.intercept_ , lr.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'Score_15':xx, 'Final Score':yy})[8:18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(xx[8:], yy[8:], c='r', lw=3, marker='s', markeredgecolor ='g', markerfacecolor='b' )\n",
    "plt.grid()\n",
    "plt.title('Predictions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try Multiple Algorithms for The Univariate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1_regressors, m1_list = getRegressors()\n",
    "scr, fitted, res = predictAll(m1_regressors, X_train, y_train, X_test,y_test,m1_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_results = display_result_runs(fitted,m1_list)\n",
    "sample_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot the different models\n",
    "sample_results.plot(figsize=(9,6))\n",
    "plt.legend(bbox_to_anchor=(1.1, 1.05))\n",
    "plt.title(' Comparing Model Predictions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare results\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted Scores across models\n",
    "scr.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This model is oversimplified - doesn't take into account the wickets !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2  - Score along with Wickets Remaining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the runs and wickets data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matchdata=pd.read_csv('/Data/IPL.csv', index_col=0)\n",
    "# Ignore super overs\n",
    "\n",
    "matchdata = matchdata [ (matchdata['Innings_No']==1)  | (matchdata['Innings_No']==2) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "matchdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### How many wickets fall by 15th over?\n",
    "cond = (matchdata['Innings_No']==1 ) & (matchdata['Ball_id_15']>=90 ) & (matchdata['Ball_id_20']>=115 )\n",
    "data = matchdata[cond]\n",
    "\n",
    "sns.distplot(data['Bowler_Wicket_15'], kde=False, color='darkred')\n",
    "plt.title('Distribution of Wickets at 15th over : No of matches '+str(data.shape[0]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a multiplier feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matchdata['Mult']= matchdata ['RUNS_20']/matchdata['RUNS_15']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Display Avg  Runs_20  at each wicket level\n",
    "cond = (matchdata['Innings_No']==1 ) & (matchdata['Ball_id_15']>=90 ) & (matchdata['Ball_id_20']>=120 )\n",
    "\n",
    "data = matchdata[cond]\n",
    "g=sns.catplot(data=data,kind = 'box',x='Bowler_Wicket_15',y='RUNS_20')\n",
    "plt.title(' Runs scored in 20 overs')\n",
    "\n",
    "#(g.set_axis_labels(\"\", \"Survival Rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Display Avg  Multiplier  at each wicket level\n",
    "cond = (matchdata['Innings_No']==1 ) & (matchdata['Ball_id_15']>=90 ) & (matchdata['Ball_id_20']>=120 )\n",
    "\n",
    "data = matchdata[cond]\n",
    "sns.catplot(data=data,kind = 'box',x='Bowler_Wicket_15',y='Mult')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(figsize=(12,6))\n",
    "cond = (matchdata['Innings_No']==1 ) & (matchdata['Ball_id_15']>=90 ) & (matchdata['Ball_id_20']>=115 )\n",
    "\n",
    "data = matchdata[cond]\n",
    "sns.scatterplot(data=data,x='RUNS_15',y='RUNS_20', hue='Bowler_Wicket_15',size='Bowler_Wicket_15',\n",
    "               sizes=(10,200),  ax=ax, palette='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scatter Diag per wicket\n",
    "\n",
    "cond = (matchdata['Innings_No']==1 ) & (matchdata['Ball_id_15']>=90 ) & (matchdata['Ball_id_20']>=115 )\n",
    "\n",
    "data = matchdata[cond]\n",
    "sns.lmplot(data=data,x='RUNS_15',y='RUNS_20', col='Bowler_Wicket_15', col_wrap=4 , palette='Blues', sharex=False, sharey=False)\n",
    "plt.ylim(0,200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = matchdata[cond]\n",
    "sns.lineplot(x='RUNS_15',y='RUNS_20', hue='Bowler_Wicket_15', data=data, ax=ax, palette='Blues_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax=sns.catplot(y='RUNS_15', x='Bowler_Wicket_15', data=data, kind='swarm',aspect=2.5, \n",
    "            label='Runs after 15 overs', legend=True)\n",
    "ax.set(title=' Runs Distribution after 15 Overs', xlabel='Wickets', ylabel='Runs in 15 overs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax=sns.catplot(y='RUNS_20', x='Bowler_Wicket_15', data=data, kind='swarm',aspect=2.5, \n",
    "            label='Runs after 20 overs', legend=True)\n",
    "ax.set(title=' Runs Distribution after 20 Overs', xlabel='Wickets', ylabel='Runs in 20 overs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matchdata['multiplier']=np.round(matchdata['RUNS_20']/matchdata['RUNS_15']-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax=sns.catplot(x='Bowler_Wicket_15', y='multiplier', data=matchdata, kind='violin', aspect=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax=sns.catplot(y='multiplier', x='Bowler_Wicket_15', data=matchdata, kind='swarm',aspect=2.5, \n",
    "            hue='Innings_No')\n",
    "ax.set(title=' % Increase in 16-20 Overs', xlabel='Wickets', ylabel='Multiplier')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax=sns.catplot(y='multiplier', x='Bowler_Wicket_15',  kind='box', col='Innings_No', data = matchdata,\n",
    "              sharey=False)\n",
    "#ax.set_xticklabels(labels=[50,100,150,200])\n",
    "#ax.set(title=' Runs Distribution after 20 Overs', xlabel='Runs in 15 Overs', ylabel='Runs in 20 overs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA Observations:\n",
    "\n",
    "For Innings 2 multipliers are really low for wicket 0/1 - this could mean that if the run chase goes well in the first 15 overs, with few wickets lost, the sense of urgency is lost as they just need to win\n",
    "\n",
    "Hence the first innings data is better for estimating 20th over score from 15th over score\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2 : Set up X and Y variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data for a three-dimensional line\n",
    "cond = (matchdata['Innings_No']==1) & (matchdata['Ball_id_15']>=90 ) & (matchdata['Ball_id_20']>=120 )\n",
    "from mpl_toolkits import mplot3d\n",
    "fig = plt.figure(figsize=(12,6))\n",
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "xdata = matchdata[cond]['Bowler_Wicket_15']\n",
    "\n",
    "ydata = matchdata[cond]['RUNS_15']\n",
    "zdata = matchdata[cond]['RUNS_20']\n",
    "ax.scatter(xdata, ydata, zdata, c=zdata, cmap='Paired_r', linewidth=0.5);\n",
    "plt.title('Final Score vs 15th over score')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond = (matchdata['Innings_No']==1) & (matchdata['Ball_id_15']>=90 ) & (matchdata['Ball_id_20']>=120 )\n",
    "# Load the features to a variable X\n",
    "X = matchdata[cond][['Bowler_Wicket_15', 'RUNS_15']]\n",
    "\n",
    "# Load the dependent variable to y\n",
    "y = matchdata[cond]['RUNS_20']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1)\n",
    "\n",
    "# Some models need scaled data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "X_scaled = scaler.fit(X)\n",
    "X_train_s=scaler.transform(X_train)\n",
    "X_test_s=scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matchdata[cond][['Bowler_Wicket_15', 'RUNS_15','RUNS_20']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test.head()\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(9,6))\n",
    "hdf=matchdata[cond][['Bowler_Wicket_15', 'RUNS_15','RUNS_20']]\n",
    "hdf.columns=['Wicket','15ov','Final']\n",
    "sns.heatmap(data=hdf.corr(), cmap='Spectral',annot=True,ax=ax, square=True, linewidths=.5, cbar=False)\n",
    "\n",
    "plt.title(\"Heatmap of Correlations\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear Model\n",
    "from sklearn import linear_model\n",
    "# Let's create an instance for the LinerRegression model\n",
    "lr = linear_model.LinearRegression()\n",
    "\n",
    "# Training the model on our train dataset\n",
    "lr.fit(X_train,y_train)\n",
    "predictions = lr.predict(X_test)\n",
    "\n",
    "from sklearn import metrics\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, predictions))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, predictions))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions)))\n",
    "print('R2:',metrics.r2_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_result(model):\n",
    "    table =[]\n",
    "\n",
    "    for score in range(100,150,5):\n",
    "        l=[score]\n",
    "        for wicket in range(1,10):\n",
    "            p= model.predict(np.array([[wicket, score]]))\n",
    "            #print(wicket,score,round(p[0]))\n",
    "            l.append(round(p[0]))\n",
    "        table.append(l)\n",
    "    result = pd.DataFrame(table, columns=['SCORE','1','2','3','4','5','6','7','8','9'])\n",
    "    return result\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_result(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg =SGDRegressor( max_iter=5 , tol=None)\n",
    "# Training the model on our train dataset\n",
    "#Use scaled values\n",
    "sg.fit(X_train_s,y_train)\n",
    "predictions = sg.predict(X_test_s)\n",
    "\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, predictions))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, predictions))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions)))\n",
    "print('R2:',metrics.r2_score(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf=RandomForestRegressor(max_depth=3, random_state=1, min_samples_leaf=10, min_samples_split=10)\n",
    "\n",
    "# Training the model on our train dataset\n",
    "rf.fit(X_train,y_train)\n",
    "predictions = rf.predict(X_test)\n",
    "\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, predictions))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, predictions))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions)))\n",
    "print('R2:',metrics.r2_score(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr=SVR(C=100)\n",
    "\n",
    "svr.fit(X_train_s,y_train)\n",
    "predictions = svr.predict(X_test_s)\n",
    "\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, predictions))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, predictions))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions)))\n",
    "print('R2:',metrics.r2_score(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = KNeighborsRegressor(n_neighbors=10)\n",
    "\n",
    "# Training the model on our train dataset\n",
    "model.fit(X_train,y_train)\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "from sklearn import metrics\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, predictions))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, predictions))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions)))\n",
    "print('R2:',metrics.r2_score(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_result(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial Reg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures(degree=2,interaction_only=True)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.fit_transform(X_test)\n",
    "lrpoly = LinearRegression(fit_intercept=False)\n",
    "lrpoly.fit(X_train_poly,y_train)\n",
    "p = lrpoly.predict(X_test_poly)\n",
    "\n",
    "\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, p))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, p))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, p)))\n",
    "print('R2:',metrics.r2_score(y_test, p))\n",
    "table =[]\n",
    "\n",
    "for score in range(100,150,5):\n",
    "    l=[score]\n",
    "    for wicket in range(1,10):\n",
    "        polyX= poly.fit_transform ( np.array([[wicket, score]]))\n",
    "        p= lrpoly.predict(polyX)\n",
    "        #print(wicket,score,round(p[0]))\n",
    "        l.append(round(p[0]))\n",
    "    table.append(l)\n",
    "\n",
    "result = pd.DataFrame(table, columns=['SCORE','1','2','3','4','5','6','7','8','9'])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build multiple models\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "def predictANN(X,y):\n",
    "\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(596, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "    model.add(layers.Dense(20, activation='relu'))\n",
    "   # model.add(layers.Dense(10, activation='relu'))\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    model.compile(optimizer='rmsprop',\n",
    "              loss='mse',\n",
    "              metrics=['mae'])\n",
    "    \n",
    "    model.fit(X_train, y_train, epochs=80, batch_size=16, verbose=0)\n",
    "    \n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    print('MAE:', metrics.mean_absolute_error(y_test, predictions))\n",
    "    print('MSE:', metrics.mean_squared_error(y_test, predictions))\n",
    "    print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions)))\n",
    "    print('R-squared' , metrics.r2_score(y_test, predictions))\n",
    "    \n",
    "    return\n",
    "\n",
    "\n",
    "def predictAll_model2(Regressors, X_train, y_train, X_test,y_test,RegList):\n",
    "\n",
    "    predictions=[]\n",
    "    cvscores=[]\n",
    "    models =[]\n",
    "    fitted_model=[]\n",
    "    y_train= y_train.ravel()\n",
    "    for regressor in Regressors:\n",
    "        model_name = type(regressor).__name__\n",
    "        models.append(model_name)\n",
    "        print(' Model', model_name)\n",
    "        regressor.fit(X_train,y_train)\n",
    "        fitted_model.append(regressor)\n",
    "        prediction = regressor.predict(X_test)\n",
    "        predictions.append(np.round(prediction))\n",
    "\n",
    "        score = cross_val_score(regressor,X_train, y_train,cv=5,scoring=\"neg_mean_squared_error\")\n",
    "        meanscore=score.mean()\n",
    "        cvscores.append(np.sqrt(-meanscore))\n",
    "        #print('CV Score',score,meanscore, np.sqrt(-meanscore))\n",
    "    \n",
    "    RMS=[]\n",
    "    R2=[]\n",
    "    \n",
    "    i=0\n",
    "    for prediction in predictions:\n",
    "        msscore = mean_squared_error(y_test, prediction)\n",
    "        r2=r2_score(y_test, prediction)\n",
    "        rms = sqrt(msscore)\n",
    "        RMS.append(rms)\n",
    "        R2.append(r2)\n",
    "       \n",
    "        i=i+1\n",
    "\n",
    "\n",
    "\n",
    "    compare = pd.DataFrame(list(zip(models,RMS,R2,cvscores)), columns=['Model','RMS','R2','CV'])\n",
    "    return fitted_model, compare.sort_values(by='RMS')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "predictANN(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2_reg, m2_list = getRegressors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_2, res_2=predictAll_model2(m2_reg, X_train, y_train, X_test,y_test,m2_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear\n",
    "display_result(fitted_2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN\n",
    "display_result(fitted_2[8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations of Model 2 Performance\n",
    "\n",
    "1. KNN - Since we do not have enough data esp for wickets 8 or 9 , KNN is giving over-optimistic results \n",
    "2. The penalty for losing wickets is best  captured by Polynomial Model but it is not very different from the linear model at low scores ( 100/9  goes to 134/135  but 145/9 goes to 177/181 )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3 : Add a Feature - Wicket Squared is added for all Models (giving benefit of Polynomial nature to all models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond = (matchdata['Innings_No']==1) & (matchdata['Ball_id_15']>=90 ) & (matchdata['Ball_id_20']>=120 )\n",
    "# Load the features to a variable X\n",
    "X1 = matchdata[cond][['Bowler_Wicket_15', 'RUNS_15']]\n",
    "\n",
    "# Load the dependent variable to y\n",
    "y = matchdata[cond]['RUNS_20']\n",
    "X1['Bowler_Wicket_15_Sq']=X1['Bowler_Wicket_15']*X1['Bowler_Wicket_15']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1, y, test_size=0.20, random_state=1)\n",
    "\n",
    "# Some models need scaled data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "scaler.fit(X1)\n",
    "X_train_s=scaler.transform(X_train)\n",
    "X_test_s=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create an instance for the LinerRegression model\n",
    "lr = linear_model.LinearRegression()\n",
    "\n",
    "# Training the model on our train dataset\n",
    "lr.fit(X_train,y_train)\n",
    "predictions = lr.predict(X_test)\n",
    "\n",
    "from sklearn import metrics\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, predictions))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, predictions))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions)))\n",
    "print('R2:', metrics.r2_score(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_result_wktsq(model):\n",
    "    table =[]\n",
    "\n",
    "    for score in range(100,150,5):\n",
    "        l=[score]\n",
    "        for wicket in range(1,10):\n",
    "            p= model.predict(np.array([[wicket, score, wicket*wicket]]))\n",
    "            #print(wicket,score,round(p[0]))\n",
    "            l.append(round(p[0]))\n",
    "        table.append(l)\n",
    "\n",
    "    result = pd.DataFrame(table, columns=['SCORE','1','2','3','4','5','6','7','8','9'])\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_result_wktsq(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try KNN\n",
    "\n",
    "\n",
    "model = KNeighborsRegressor(n_neighbors=10)\n",
    "\n",
    "# Training the model on our train dataset\n",
    "model.fit(X_train,y_train)\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "from sklearn import metrics\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, predictions))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, predictions))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions)))\n",
    "print('R2:', metrics.r2_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_result_wktsq(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Multiple Models for Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_3, res_3=predictAll_model2(m2_reg, X_train, y_train, X_test,y_test,m2_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Elastic \n",
    "display_result_wktsq(fitted_3[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN\n",
    "display_result_wktsq(fitted_3[8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations of Model3 \n",
    "\n",
    "The penalty for losing wickets is better captured by Model 3\n",
    "\n",
    "In Elastic Net, 100/9 after 15 overs is going to 126 in 20 overs; 145/9 is going to 174\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion :\n",
    "\n",
    "####  1. The IPL games have few data points where games have gone to 20 overs completion after 8 or 9 wickets have fallen in 15 overs - so the models are not able to capture this scenario\n",
    "\n",
    "#### 2.  The acceleration of scores from the 15th to 20th over highly  depends on the playing conditions and this model doesn't capture the same\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Tuning RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "param_grid = {  \n",
    "              \"max_depth\" : [ 3,  2],\n",
    "              \"min_samples_leaf\" : [ 5,  10, 20], \n",
    "              \"min_samples_split\" : [  10,  15], \n",
    "              \"n_estimators\": [100, 50,  10],\n",
    "              \"max_features\" : [\"auto\", \"sqrt\"]}\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "gsRF = GridSearchCV(rf,param_grid = param_grid, cv=5, scoring=\"explained_variance\", n_jobs= 4, verbose = 1)\n",
    "\n",
    "gsRF.fit(X, y)        \n",
    "\n",
    "rf_best = gsRF.best_estimator_\n",
    "\n",
    "print(gsRF.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gsRF.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random\n",
    "display_result_wktsq(Regressors[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
