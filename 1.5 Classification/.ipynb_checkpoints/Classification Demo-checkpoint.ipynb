{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Machine Learning Systems - (Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions to display a video or an image \n",
    "from IPython.display import HTML\n",
    "def display_video(src):\n",
    "    print('Source : '+src+ '?autoplay=1;modestbranding=1;rel=0')\n",
    "    return HTML('<iframe width=\"800\" height=\"400\" src=' + src + '?autoplay=1;modestbranding=1;rel=0 frameborder=\"0\" allowfullscreen></iframe>')\n",
    "\n",
    "def display_image(src):\n",
    "    print('Source : '+src)\n",
    "    return HTML('<img width=\"600\" height=\"300\" src=' + src + '></img>')\n",
    "\n",
    "def displayResults (y_test, predictions, n=10):\n",
    "    Results = pd.DataFrame({'Actual': y_test})\n",
    "    column = pd.DataFrame({'Predictions': predictions})\n",
    "    Results = Results.join(column.set_index(Results.index))\n",
    "    return Results.head(n)\n",
    "\n",
    "def display_cm(cm):\n",
    "    plt.clf()\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Wistia)\n",
    "    classNames = ['Benign','Malignant']\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    tick_marks = np.arange(2)\n",
    "    plt.xticks(tick_marks, classNames, rotation=45)\n",
    "    plt.yticks(tick_marks, classNames)\n",
    "    s = [['TN','FP'], ['FN', 'TP']]\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            plt.text(j,i, str(s[i][j])+\" = \"+str(cm[i][j]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a Classification Problem ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We briefly talked about Classification problem in our previous notebook.\n",
    "\n",
    "1. **Independent Variables for classification** - These are also called features of our dataset. They are the variables which when varied can affect our target classes that we want to predict.\n",
    "2. **Dependent Variable for classification** - When your target variable has certain class labels, its a classification problem. For instance classifying pictures of dogs and cats or a tumour to be cancerous or non cancerous etc. You are not predicting a continuous quantity here but different classes.\n",
    "\n",
    "Lets take an example to understand it clearly :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> [Breast Cancer Diagnostic] </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two main classifications of tumors. One is known as benign and the other as malignant. A benign tumor is a tumor that does not invade its surrounding tissue or spread around the body. A malignant tumor is a tumor that may invade its surrounding tissue or spread around the body."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image('https://www.verywellhealth.com/thmb/xnYC1DVmfPtwjWCEdO0HjSZbcBo=/1787x0/filters:no_upscale():max_bytes(150000):strip_icc():format(webp)/514240-article-img-malignant-vs-benign-tumor2111891f-54cc-47aa-8967-4cd5411fdb2f-5a2848f122fa3a0037c544be.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our target it to train a Logistic Regression model that can predict whether the cancer is benign (B) or malignant (M)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attribute Information:\n",
    "<br>1) ID number \n",
    "<br>2) Diagnosis (M = malignant, B = benign) \n",
    "<br>3-32) Ten real-valued features are computed for each cell nucleus: \n",
    "<br>a) radius (mean of distances from center to points on the perimeter) \n",
    "<br>b) texture (standard deviation of gray-scale values) \n",
    "<br>c) perimeter \n",
    "<br>d) area \n",
    "<br>e) smoothness (local variation in radius lengths) \n",
    "<br>f) compactness (perimeter^2 / area - 1.0) \n",
    "<br>g) concavity (severity of concave portions of the contour) \n",
    "<br>h) concave points (number of concave portions of the contour) \n",
    "<br>i) symmetry \n",
    "<br>j) fractal dimension (\"coastline approximation\" - 1)\n",
    "\n",
    "**`'Diagnosis'`** column is the **Dependent Variable or target column** because we want our algorithm to predict this class.\n",
    "\n",
    "**`'1,3-32'`** are your **Features or Independent Variables** which will help you predict the Benign/Malignant class. Vary any one of them and it is going to affect your Diagnostic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Intuition "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will discuss about the Logistic Regression algorithm. Don't be confused by the name \"Logistic Regression\"; it is named that way for historical reasons and is actually an approach to classification problems, not regression problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of our output vector y being a continuous range of values, it will only be 'M' or 'B'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the CSV file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loding the dataset into pandas dataframe and print the sample of first 5 rows\n",
    "df = pd.read_csv('/Data/Breast_Cancer_Diagnostic.csv')\n",
    "df.sample(n=5, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['diagnosis'] = df.diagnosis.apply(lambda x: 1 if x == 'M' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(n=5, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*We will only consider ten real-valued features in this project for diagnostic!<br>\n",
    "Let's separate the required features along with diagnosis column.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['radius_mean', 'texture_mean', 'perimeter_mean',\n",
    "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
    "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean','diagnosis']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['diagnosis'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if Any Null Values are there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns[df.isnull().any()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load X and Y variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the features to a variable X\n",
    "# x is created by simply dropping the diagnosis column and retaining all others\n",
    "X = df.drop('diagnosis', axis = 1)\n",
    "# Load the dependent variable to y\n",
    "y = df['diagnosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Test Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**> Train-Test split -** We split our data into two parts, namely, the train set and the test set (ideally its a 70-30 train-test split which is upto you). We then try to build our function f(x) (aka model) using the train set and see how well it does on the test set.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an Instance of the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create an instance for the LogisticRegression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "Classifier = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Model using Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model on our train dataset\n",
    "Classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_proba = Classifier.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting predictions from the model \n",
    "y_test_hat = Classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all = pd.DataFrame({'Prob(y_test==1)': predictions_proba[:,1], 'y_test_hat': y_test_hat, 'y_test': y_test})\n",
    "all.sample(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation Techniques for Classification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. The  Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting classification report\n",
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(y_test,y_test_hat)\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. The confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score\n",
    " \n",
    "cm = confusion_matrix(y_test, y_test_hat)\n",
    "display_cm(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculations \n",
    "\n",
    "TN = cm[0,0]\n",
    "FP = cm[0,1]\n",
    "FN = cm[1,0]\n",
    "TP = cm[1,1]\n",
    "\n",
    "accuracy = (TP+TN) / float(TP+TN+FN + FP)\n",
    "print('Accuracy ',accuracy)\n",
    "\n",
    "sensitivity = TP / float(FN + TP)\n",
    "print('sensitivity or recall (Malignant Predictions):',sensitivity)\n",
    "\n",
    "specificity = TN / (TN + FP)\n",
    "print('specificity(Benign Class)',specificity)\n",
    "\n",
    "precision = TP / float(TP + FP)\n",
    "print('precision',precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Positive Predictive Value or Precision : \n",
    " When a positive value is predicted, how often is the prediction correct?\n",
    "<br> How \"precise\" is the classifier when predicting positive instances?\n",
    "<br><b>Sensitivity or Recall or True Positive Rate:</b> \n",
    "<br>When the actual value is positive, how often is the prediction correct?\n",
    "<br>Something we want to maximize and Minimise FN\n",
    "<br>How \"sensitive\" is the classifier to detecting positive instances?\n",
    "<br>Also known as \"True Positive Rate\" or \"Recall\"\n",
    "<br>TP / TP + FN (all positive)\n",
    "#### Specificity:  When the actual value is negative, how often is the prediction correct?\n",
    "Something we want to maximize\n",
    "<br>How \"specific\" (or \"selective\") is the classifier in predicting positive instances?\n",
    "<br>TN / TN + FP (all negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:**\n",
    "<br>Our model is specific but not that sensitive.\n",
    "<br>Confusion matrix gives you a more complete picture of how your classifier is performing\n",
    "<br>Also allows you to compute various classification metrics, and these metrics can guide your model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Which metrics should you focus on?\n",
    "\n",
    "Choice of metric depends on your business objective\n",
    "Identify if FP or FN is more important to reduce\n",
    "Choose metric with relevant variable (FP or FN in the equation)\n",
    "Spam filter (positive class is \"spam\"):\n",
    "Optimize for precision or specificity\n",
    "precision\n",
    "false positive as variable\n",
    "specificity\n",
    "false positive as variable\n",
    "Because false negatives (spam goes to the inbox) are more acceptable than false positives (non-spam is caught by the spam filter)\n",
    "Fraudulent transaction detector (positive class is \"fraud\"):\n",
    "Optimize for sensitivity\n",
    "FN as a variable\n",
    "Because false positives (normal transactions that are flagged as possible fraud) are more acceptable than false negatives (fraudulent transactions that are not detected)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
